import os
import re
import json
import pickle
import numpy as np
import pandas as pd
from datetime import datetime
import cv2
from constants import *
import torch
from torch.utils.data import Dataset

USE_SEQUENCE_LABEL = False  # âœ… æ§åˆ¶æ˜¯å¦ä½¿ç”¨åºåˆ—æ ‡ç­¾ï¼ˆFalse = ä½¿ç”¨å¸§æ ‡ç­¾ï¼‰

class ThermalBlinkDataset(Dataset):
    def __init__(
            self,
            pkl_root: str,
            csv_root: str,
            subfolders: list,
            val_pkl_dir: str = None,
            val_csv_dir: str = None,
            is_val: bool = False,
            center_size: tuple = (12, 16),
    ):
        """
        Args:
            pkl_root: çƒ­å›¾æ•°æ®æ ¹ç›®å½•
            csv_root: blinkæ ‡æ³¨csvæ–‡ä»¶ç›®å½•
            subfolders: å­æ–‡ä»¶å¤¹åˆ—è¡¨ï¼Œå¦‚ ["0503", "0505"]
            val_pkl_dir: éªŒè¯é›†å•ç‹¬pklè·¯å¾„(is_val=Trueæ—¶å¯ç”¨)
            val_csv_dir: éªŒè¯é›†å¯¹åº”csvè·¯å¾„(is_val=Trueæ—¶å¯ç”¨)
            is_val: æ˜¯å¦æ˜¯éªŒè¯é›†
            center_size: ä¸­å¿ƒè£å‰ªåŒºåŸŸå¤§å°ï¼Œé»˜è®¤(12,16)
        """
        self.center_size = center_size
        self.data = []

        if is_val:
            # åªåŠ è½½ä¸€å¯¹ val pkl + csv
            for filename in os.listdir(val_pkl_dir):
                if not filename.endswith(".pkl"):
                    continue
                pkl_path = os.path.join(val_pkl_dir, filename)
                match = re.match(r"(.*_\d{8}_\d{4})", filename)
                if not match:
                    continue
                fuzzy_key = match.group(1)
                matched_csvs = [
                    f for f in os.listdir(val_csv_dir)
                    if f.startswith("blink_offsets_") and fuzzy_key in f and f.endswith(".csv")
                ]
                if not matched_csvs:
                    continue
                csv_path = os.path.join(val_csv_dir, matched_csvs[0])
                frames, labels, timestamps = self.process_sample(pkl_path, csv_path, return_timestamps=True)
                if frames is not None:
                    N = frames.shape[0]
                    if WINDOW_MODE:
                        for i in range(0, N - FRAME_STACK_SIZE + 1, 1):
                            window = frames[i:i+FRAME_STACK_SIZE].squeeze(-1)  # [FRAME_STACK_SIZE, H, W]
                            label = float(np.any(labels[i:i+FRAME_STACK_SIZE] == 1.0)) 
                            self.data.append((window, label, None))
                    else:
                        for i in range(N):
                            frame = frames[i].squeeze(-1)  # [H, W]
                            self.data.append((frame[np.newaxis, ...], labels[i], None))  # [1, H, W]
        else:
            # æ‰¹é‡åŠ è½½è®­ç»ƒé›†
            for subfolder in subfolders:
                pkl_dir = os.path.join(pkl_root, subfolder)
                for filename in os.listdir(pkl_dir):
                    if not filename.endswith(".pkl"):
                        continue
                    pkl_path = os.path.join(pkl_dir, filename)
                    if val_pkl_dir and pkl_path == val_pkl_dir:
                        continue  # æ’é™¤éªŒè¯é›†æ–‡ä»¶
                    base_name = os.path.splitext(filename)[0]  # å»æ‰ .pkl åç¼€
                    parts = base_name.split('_')
                    fuzzy_key = parts[-3] + "_" + parts[-2][:4]

                    # å» gt_output çš„å­ç›®å½•ä¸­åŒ¹é…å¯¹åº” CSV
                    csv_subdir = os.path.join(csv_root, subfolder)
                    if not os.path.exists(csv_subdir):
                        print(f"[WARN] CSV å­ç›®å½•ä¸å­˜åœ¨: {csv_subdir}")
                        continue
                    matched_csvs = [
                        f for f in os.listdir(csv_subdir)
                        if f.startswith("blink_offsets_") and fuzzy_key in f and f.endswith(".csv")
                    ]
                    if not matched_csvs:
                        print(f"[WARN] æœªåŒ¹é…åˆ° CSV: {fuzzy_key} in {csv_subdir}")
                        continue
                    csv_path = os.path.join(csv_subdir, matched_csvs[0])
                    frames, labels, _ = self.process_sample(pkl_path, csv_path, return_timestamps=False)
                    if frames is not None:
                        N = frames.shape[0]
                        if WINDOW_MODE:
                            # æ­£ç¡®çš„æ»‘åŠ¨çª—å£å †å 
                            for i in range(0, N - FRAME_STACK_SIZE + 1, 1):
                                window = frames[i:i+FRAME_STACK_SIZE].squeeze(-1)  # [FRAME_STACK_SIZE, H, W]
                                label = float(np.any(labels[i:i+FRAME_STACK_SIZE] == 1.0))
                                self.data.append((window, label, None))
                        else:
                            for i in range(N):
                                frame = frames[i].squeeze(-1)  # [H, W]
                                label = labels[i]
                                self.data.append((frame[np.newaxis, ...], label, None))  # [1, H, W]

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        x, y, _ = self.data[idx]
        if WINDOW_MODE:
            # x: [FRAME_STACK_SIZE, H, W]ï¼Œy: float
            x = torch.tensor(x, dtype=torch.float32)  # [T, H, W]
            y = torch.tensor(y, dtype=torch.float32)  # æ ‡é‡
            return {"x": x, "y": y}
        else:
            # x: [1, H, W]ï¼Œy: float
            x = torch.tensor(x, dtype=torch.float32)  # [1, H, W]
            y = torch.tensor(y, dtype=torch.float32)  # æ ‡é‡
            return {"x": x, "y": y}

    def assign_frame_labels(self, timestamps, blink_starts, blink_ends):
        """
        æŒ‰å¸§æ‰“æ ‡ç­¾ï¼Œstart ~ end åŒºé—´ä¸º 1ï¼Œå…¶ä»–ä¸º 0
        """
        labels = np.zeros_like(timestamps, dtype=np.float32)
        for start, end in zip(blink_starts, blink_ends):
            labels[(timestamps >= start) & (timestamps <= end)] = 1.0
        return labels


    def process_sample(self, pkl_path, csv_path, return_timestamps=False):
        try:
            with open(pkl_path, "rb") as f:
                data = pickle.load(f)
            if not ('temperature' in data and 'timestamp' in data):
                print(f"[ERROR] ç¼ºå­—æ®µ: {pkl_path}")
                return None, None, None
        except Exception as e:
            print(f"[ERROR] pkl è¯»å–å¤±è´¥: {pkl_path}\n{e}")
            return None, None, None

        df = pd.read_csv(csv_path)
        offsets = {row['key']: json.loads(row['value']) for _, row in df.iterrows()}
        blink_start_offsets = offsets["start_offsets"]
        blink_end_offsets = offsets["end_offsets"]
        # âœ… å¦‚æœèµ·å§‹æ•°é‡ä¸ä¸€è‡´ï¼Œä¸” end çš„ç¬¬ä¸€å¸§åœ¨ start ä¹‹å‰ï¼Œåˆ™è¡¥ 0
        if len(blink_start_offsets) != len(blink_end_offsets):
            print(f"[WARN] ä¿®æ­£ä¸­: {os.path.basename(pkl_path)}")
        
            # ğŸ‘‰ å¦‚æœ end æ¯” start å¤šï¼Œè¯´æ˜ç¼ºå°‘èµ·å§‹ï¼Œè¡¥ 0
            if len(blink_end_offsets) > len(blink_start_offsets):
                blink_start_offsets = [0] + blink_start_offsets
                print(f"â• æ’å…¥ start=0")
        
            # ğŸ‘‰ å¦‚æœ start æ¯” end å¤šï¼Œè¯´æ˜ç¼ºå°‘ç»“æŸï¼Œè¡¥æœ€åä¸€å¸§æ—¶é—´
            elif len(blink_start_offsets) > len(blink_end_offsets):
                last_offset = (datetime.fromisoformat(data['timestamp'][-1]) - datetime.fromisoformat(
                    data['timestamp'][0])).total_seconds() * 1000
                blink_end_offsets.append(int(last_offset))
                print(f"â• è¡¥å…… end={int(last_offset)}")
        
        # å†æ¬¡æ£€æŸ¥æ˜¯å¦å¯¹é½
        if len(blink_start_offsets) != len(blink_end_offsets):
            print(f"[ERROR] ä¿®æ­£åä»ä¸ä¸€è‡´: {pkl_path}")
            print(len(blink_start_offsets), len(blink_end_offsets))
            return None, None, None


        # temperature_frames = np.array(data['temperature'])  # [N, 12, 16]
        raw_frames = np.array(data['temperature'])  # [N, H, W]

        # âœ… Step A: ç»Ÿä¸€é¢„å¤„ç†å¹¶ clip åˆ°å›ºå®šèŒƒå›´ [-3, 3]
        enhanced_all = []
        for frame in raw_frames:
            # â‘  é«˜æ–¯æ»¤æ³¢
            blurred = cv2.GaussianBlur(frame, (3, 3), sigmaX=0.5)
            # â‘¡ æ ‡å‡†å·®å½’ä¸€åŒ–
            enhanced = (blurred - np.mean(blurred)) / (np.std(blurred) + 1e-5)
            enhanced_all.append(enhanced)

        # âœ… å›ºå®š clip èŒƒå›´
        global_min = -3.0
        global_max = 2.0
        print(f"ğŸŒ¡ï¸ ä½¿ç”¨ç»Ÿä¸€å¢å¼ºèŒƒå›´: min={global_min}, max={global_max}")
        processed = []
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2,2))
        for e in enhanced_all:
            c   = np.clip(e, global_min, global_max)
            n01 = (c - global_min) / (global_max - global_min)
            g   = np.power(n01, 0.5) # gamma 0.5
            u8  = (g * 255).astype(np.uint8)
            ce  = clahe.apply(u8).astype(np.float32) / 255.0
            processed.append(ce)
        frames_np = np.stack(processed, axis=0)  # [N, H, W]


        # 5. æ—¶é—´æˆ³ & å¸§çº§æ ‡ç­¾
        ts_list = [datetime.fromisoformat(t) for t in data['timestamp']]
        base = ts_list[0]
        timestamps = np.array([(t - base).total_seconds() * 1000 for t in ts_list], dtype=np.float32)
        frame_labels = self.assign_frame_labels(timestamps, blink_start_offsets, blink_end_offsets)
        
        # ä¸­å¿ƒè£å‰ª
        h, w = frames_np[0].shape
        ch, cw = self.center_size
        sr = h // 2 - ch // 2
        er = sr + ch
        sc = w // 2 - cw // 2
        ec = sc + cw
        cropped_frames = frames_np[:, sr:er, sc:ec]  # [N, H', W']
        X = cropped_frames[..., np.newaxis]  # [N, H', W', 1]


        if return_timestamps:
            return X, frame_labels, timestamps
        else:
            return X, frame_labels, None

